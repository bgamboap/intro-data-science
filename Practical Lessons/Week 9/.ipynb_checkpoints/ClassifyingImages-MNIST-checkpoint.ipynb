{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification: images. The MNIST example\n",
    "\n",
    "In this example we will use the (now) classic MNIST dataset. The task is very simple. Given images of manually drawn images, learn a classifier that is able to decide which is the digit drawn. This is a classification problem with 10 classes (0, 1, 2, 3, ..., 9).\n",
    "\n",
    "I will use examples from several sources. Mostly notebooks from kaggle contributors.\n",
    "https://www.kaggle.com/hamzaboulahia/logistic-regression-mnist-classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "#advanced statistical graphs\n",
    "import seaborn as sb \n",
    "%matplotlib inline \n",
    "# With this backend, the output of plotting commands is displayed inline within frontends like the Jupyter notebook, directly below the code cell that produced it. The resulting plots will then also be stored in the notebook document.\n",
    "\n",
    "from scipy.io import loadmat\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data\n",
    "\n",
    "This dataset contains images with dimensions 28 x 28. Images can be stored in many different formats like CSV, jpeg, etc. In this dataset images are stored as `mat`. This is matlab's format. Matlab is a famous software for mathematics, statistics and ML. It is very powerful but proprietary having a payed license. Matlab has its own programming language. \n",
    "\n",
    "We load the data with the `loadmat`function provided by the **module** `io` from the **package** `scipy`. In Portuguese: m√≥dulo and pacote. We can also use the more generic term `library` (biblioteca).\n",
    "\n",
    "This loading operation stores the data in memory as a matrix with 28x28=784 columns and as many lines as images. Each line is an image and contains values between 0 and 255 indicating a level of gray (or any other scale you may enjoy). This is a **convenient representation** since now we have the data in the tabular format that all the methods we have seen so far use.\n",
    "\n",
    "In other words, we have **transformed images** into a numeric table that can be stored as a matrix or a data frame. The attributes are the pixels. The first one is the top-left pixel, followed by all the pixels on the top of the image, followed by the next line of the image, until the bottom right pixel.\n",
    "\n",
    "This way, we can **transform images into a regular data set** and apply any method. Well, results may not be the best. But that is another issue.\n",
    "\n",
    "The `T` function transposes the matrix data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 784)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading MNIST data\n",
    "\n",
    "mnist = loadmat(\"mnist-original.mat\")\n",
    "mnist_data = mnist[\"data\"].T\n",
    "mnist_label = mnist[\"label\"][0]\n",
    "mnist_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking at the data\n",
    "\n",
    "We can see that we have 70k images. We will now look at the numbers in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]], dtype=uint8),\n",
       " array([0., 0., 0., ..., 9., 9., 9.]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_data, mnist_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  51, 159, 253,\n",
       "       159,  50,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  48, 238,\n",
       "       252, 252, 252, 237,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  54,\n",
       "       227, 253, 252, 239, 233, 252,  57,   6,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  10,\n",
       "        60, 224, 252, 253, 252, 202,  84, 252, 253, 122,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0, 163, 252, 252, 252, 253, 252, 252,  96, 189, 253, 167,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,  51, 238, 253, 253, 190, 114, 253, 228,  47,  79, 255,\n",
       "       168,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,  48, 238, 252, 252, 179,  12,  75, 121,  21,   0,\n",
       "         0, 253, 243,  50,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,  38, 165, 253, 233, 208,  84,   0,   0,   0,\n",
       "         0,   0,   0, 253, 252, 165,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   7, 178, 252, 240,  71,  19,  28,   0,\n",
       "         0,   0,   0,   0,   0, 253, 252, 195,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,  57, 252, 252,  63,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0, 253, 252, 195,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0, 198, 253, 190,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0, 255, 253, 196,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  76, 246, 252,\n",
       "       112,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 253, 252,\n",
       "       148,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  85,\n",
       "       252, 230,  25,   0,   0,   0,   0,   0,   0,   0,   0,   7, 135,\n",
       "       253, 186,  12,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,  85, 252, 223,   0,   0,   0,   0,   0,   0,   0,   0,   7,\n",
       "       131, 252, 225,  71,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,  85, 252, 145,   0,   0,   0,   0,   0,   0,   0,\n",
       "        48, 165, 252, 173,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,  86, 253, 225,   0,   0,   0,   0,   0,\n",
       "         0, 114, 238, 253, 162,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,  85, 252, 249, 146,  48,  29,\n",
       "        85, 178, 225, 253, 223, 167,  56,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,  85, 252, 252, 252,\n",
       "       229, 215, 252, 252, 252, 196, 130,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  28, 199,\n",
       "       252, 252, 253, 252, 252, 233, 145,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,  25, 128, 252, 253, 252, 141,  37,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0], dtype=uint8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the first image\n",
    "mnist_data[0,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seeing the data\n",
    "\n",
    "In fact we can visualize each line as an image. We can do that with fancy plotting, but first we will do it with plain python (this works in very old screens). Try out with different lines and discover each of which class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "............................\n",
      "............................\n",
      "............................\n",
      "............................\n",
      "...............xxxxx........\n",
      "..............xxxxxx........\n",
      ".............xxxxxxxx.......\n",
      "............xxxxxxxxxx......\n",
      "...........xxxxxxxxxxx......\n",
      "..........xxxxxxxxxxxx......\n",
      ".........xxxxxxxxx..xxx.....\n",
      "........xxxxxx......xxx.....\n",
      "........xxxxxx......xxx.....\n",
      ".......xxxx.........xxx.....\n",
      ".......xxx..........xxx.....\n",
      "......xxxx..........xxx.....\n",
      "......xxxx.........xxxx.....\n",
      "......xxx.........xxxx......\n",
      "......xxx.......xxxx........\n",
      "......xxx......xxxx.........\n",
      "......xxxxxxxxxxxxx.........\n",
      "......xxxxxxxxxxx...........\n",
      "......xxxxxxxxx.............\n",
      ".......xxxxxxx..............\n",
      "............................\n",
      "............................\n",
      "............................\n",
      "............................\n"
     ]
    }
   ],
   "source": [
    "case = 0\n",
    "x = mnist_data[case,:]\n",
    "print(mnist_label[case])\n",
    "for line in range(28):\n",
    "    for col in range(28):\n",
    "        if(x[line*28+col]>10):\n",
    "            print('x', end='')\n",
    "        else:\n",
    "            print('.', end='')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## True plotting\n",
    "\n",
    "We can see the images in any scale of color."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_random_example():\n",
    "    idx = np.random.randint(70000)\n",
    "    exp = mnist_data[idx].reshape(28,28)\n",
    "    print(\"The number in the image below is:\", mnist_label[idx])\n",
    "    plt.imshow(exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number in the image below is: 2.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mnist_random_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the training set feature matrix is: (3500, 784)\n",
      "The shape of the training label vector is: (3500,)\n",
      "The shape of the test set feature matrix is: (3500, 784)\n",
      "The shape of the test label vector is: (3500,)\n"
     ]
    }
   ],
   "source": [
    "# Splitting the data into Train and Test datasets\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(mnist_data, mnist_label, train_size=0.05, test_size=0.05, random_state=42)\n",
    "print(\"The shape of the training set feature matrix is:\", X_train.shape)\n",
    "print(\"The shape of the training label vector is:\", Y_train.shape)\n",
    "print(\"The shape of the test set feature matrix is:\", X_test.shape)\n",
    "print(\"The shape of the test label vector is:\", Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=2, kernel='poly')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "model = SVC(kernel='poly', C=2) #porque SVC pode fazer classifica√ß√£o de muitas clacsses e n√£o s√≥ classe bin√°ria\n",
    "model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9242857142857143"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifiers\n",
    "\n",
    "Although this is an image classification problem, it is set an a way that makes it relatively easy. Never the less we see that different classifiers may have more or less difficulty in dealing with this problem.\n",
    "\n",
    "### Decision trees\n",
    "\n",
    "1. Try the decision tree algorithm with a low `max_depth`. This is not the kind of data for decision trees. However, it is a very efficient algorithm that obtains results well above random. \n",
    "2. Use other parameters like complexity (`ccp_alpha`). The highest the complexity the more it takes the size of the tree into account. A large complexity will force the tree to be minimal (it is like using a very small max_depth). https://scikit-learn.org/stable/modules/tree.html#minimal-cost-complexity-pruning\n",
    "2. Look at the confusion matrix. Which classes are mistaken in decision trees and in SVM?\n",
    "4. Does decision tree improve with the number of training examples? What about SVM?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7371428571428571"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "model = tree.DecisionTreeClassifier(ccp_alpha=0)\n",
    "model.fit(X_train,Y_train)\n",
    "model.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[252,   1,  15,   9,   2,  13,  10,   5,   4,   9],\n",
       "       [  1, 349,   7,   8,   2,   2,   2,   4,  10,   2],\n",
       "       [  6,   6, 248,  17,   8,  10,  11,  20,  19,   7],\n",
       "       [  7,  10,   6, 249,   5,  29,   3,  10,  18,  19],\n",
       "       [  1,   5,   5,   7, 239,   4,  12,  12,  18,  26],\n",
       "       [ 13,   4,   9,  31,  14, 201,  22,  15,  19,  14],\n",
       "       [  9,   7,  23,   6,   8,  18, 288,   6,   7,   5],\n",
       "       [  5,   2,  14,   5,   7,   2,   1, 294,  11,  19],\n",
       "       [  5,   8,  29,  15,  13,  18,  14,   4, 209,  22],\n",
       "       [  4,   4,   5,   8,  33,  12,  11,  21,  16, 226]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "Y_pred = model.predict(X_test)\n",
    "confusion_matrix(Y_test, Y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrix:\n",
    "\n",
    "linhas - previsto\n",
    "\n",
    "colunas - real\n",
    "\n",
    "somar por colunas diz me quantos tenho em cada classe - se estiver na diagonal quer dizer que classifiquei corretamente como da classe certa, os que estiverem na mesma coluna mas linhas diferentes √© porque classifiquei incorretamente como da classe correspondendo a essa coluna\n",
    "\n",
    "verificar se reais √© linhas ou colunas - acho que √© linhas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other classifiers\n",
    "\n",
    "Logistic Regression does a good job here as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bea/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8454285714285714"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression(random_state=0).fit(X_train, Y_train)\n",
    "model.score(X_test, Y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[287,   0,   4,   8,   1,   6,   4,   2,   7,   1],\n",
       "       [  0, 377,   5,   2,   0,   1,   0,   0,   1,   1],\n",
       "       [  3,  12, 283,  16,   1,   5,   7,   6,  19,   0],\n",
       "       [  8,   2,   8, 292,   0,  24,   1,   5,  12,   4],\n",
       "       [  1,   3,   2,   0, 290,   1,   7,   9,   5,  11],\n",
       "       [ 10,   5,   5,  30,   4, 242,   8,   3,  31,   4],\n",
       "       [  6,   3,   6,   2,   1,   9, 348,   0,   1,   1],\n",
       "       [  7,   2,   4,   3,   9,   0,   0, 314,   2,  19],\n",
       "       [ 10,  15,   8,  10,   4,  14,   6,   4, 258,   8],\n",
       "       [  4,   4,   1,   7,  29,   4,   0,  18,   5, 268]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred = model.predict(X_test)\n",
    "confusion_matrix(Y_test, Y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi layer perceptron\n",
    "\n",
    "This data is low level. Therefore it would benefit from using hidden layers that abstract the input atrributes. Given that we have 728 low level input attributes, we would gain from having hidden layers with lower numbers of units. How many layers? It is hard to tell but we can imagine a first layer of abstraction with point blobs, a second layer with lines and arches and a perhaps third with a combination of these. But maybe the third layer is jard to justify. The sizes of the layers should decrease from input to output to force abstraction. But this is speculation that would have to be checked with the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9217142857142857"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "model = MLPClassifier(random_state=1, \n",
    "                    hidden_layer_sizes=(500,250,),\n",
    "                    max_iter=1000,verbose=0,tol=0.001,\n",
    "                   activation='logistic').fit(X_train, Y_train)\n",
    "model.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "\n",
    "In abstract, we can apply any classifier. With low level data and many attributes, SVM and NN tend to have a better performance than decision trees. DT are best suited for high level data. Logistic regression works well with many attributes but has difficulty in finding linear boundaries for this data. In the Machine Learning course or in Computer Vision you will see that there are Neural Networks that are designed to work with images. Namely the Convolutional Neural Networks.\n",
    "\n",
    "1. How robust are the methods to noise? You can introduce random noise in the examples and see how they behave. Noise can be introduced in different ways. a) By randomly assigning a number between o and 255 to random position of the examples. b) by adding columns with random data to all the cases."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
